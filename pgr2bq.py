import argparse
import csv
import json
import re

from geomet import wkb, wkt


def converter(type_converter, null_value="null"):
    def func(val):
        if val == null_value:
            return None
        return type_converter(val)
    return func


def convert_wkb_to_wkt(strip_srid=True):
    def func(wkb_hex_value):
        geom = wkb.loads(bytes.fromhex(wkb_hex_value))
        if strip_srid:
            geom.pop("meta")
            geom.pop("crs")
        return wkt.dumps(geom)
    return func


TABLE_SCHEMA = {
    "id": converter(int),
    "osm_id": converter(int),
    "osm_name": converter(str),
    "osm_meta": converter(str),
    "osm_source_id": converter(int),
    "osm_target_id": converter(int),
    "clazz": converter(int),
    "flags": converter(int),
    "source": converter(int),
    "target": converter(int),
    "km": converter(float),
    "kmh": converter(int),
    "cost": converter(float),
    "reverse_cost": converter(float),
    "x1": converter(float),
    "y1": converter(float),
    "x2": converter(float),
    "y2": converter(float),
    "geom_way": converter(convert_wkb_to_wkt(strip_srid=True))
}


def main(input_file, output_file, output_format):
    # Find and convert values after INSERT INTO ... VALUES to CSV
    insert_lines = []
    with open(input_file, "r") as in_fp:
        for line in in_fp:
            insert_line = re.search(r"^\((.*?)\),?$", line)
            if insert_line:
                insert_lines.append(insert_line.group(1))

    # Read CSV lines
    csv.register_dialect("sql", skipinitialspace=True, quotechar="'")
    csv_data = csv.DictReader(insert_lines, fieldnames=TABLE_SCHEMA.keys(), dialect="sql")
    with open(output_file, "w") as out_fp:
        if output_format == "csv":
            writer = csv.DictWriter(out_fp, fieldnames=TABLE_SCHEMA.keys())
            writer.writeheader()
            for data in csv_data:
                data = {k: TABLE_SCHEMA[k](v) for k, v in data.items()}
                writer.writerow(data)
        if output_format == "json":
            for data in csv_data:
                data = {k: TABLE_SCHEMA[k](v) for k, v in data.items()}
                out_fp.write(json.dumps(data) + "\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", default="sample.sql", help="Path to PgRouting SQL file generated by osm2po")
    parser.add_argument("--output", default=None, help="Output file")
    parser.add_argument("--format", default="json", help="Output format: JSON (default) or CSV")
    args = parser.parse_args()

    input_file = args.input
    output_file = args.output
    output_format = args.format
    if not args.output:
        filename, _, ext = input_file.rpartition(".")
        output_file = filename + "." + output_format.lower()
    main(input_file, output_file, output_format)
